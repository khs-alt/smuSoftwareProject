{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXFsxhRJHiUI",
    "outputId": "bda36300-ad0e-412b-85c6-00f7488532ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.5)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting triton==2.0.0 (from openai-whisper)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/e7/69/d228b38ffb70858d74538bdfe5aa18c7640b7f07840239690985b3a94009/numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (8.12.0)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
      "Collecting cmake (from triton==2.0.0->openai-whisper)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/72/89/b1cf3cd5fb9f4ae796dd4a743412553f884dad2acbf6b9828d3a0c2b5524/cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper) (3.9.0)\n",
      "Collecting lit (from triton==2.0.0->openai-whisper)\n",
      "  Downloading lit-17.0.2.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/154.6 kB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper)\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/50/df/38c9fb5cc64f4fcc0577a14a0665c2a5de74f45a621ac7708320b1ac80c6/llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper, lit\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=4327352e2dc9142bf945a8833e1e168aa007cc6a3491f2ed27ced1aa5b3562a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.2-py3-none-any.whl size=93257 sha256=90a4c66cc12bb5bac2ba7d0e181110c385bb572b9f646377f77c42e7f9912937\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/3a/ff/73/ce1a12d89231e9ac175fb6493ee1fcc8768e85ee3bea4b98b2\n",
      "Successfully built openai-whisper lit\n",
      "Installing collected packages: lit, cmake, numpy, llvmlite, tiktoken, numba, triton, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "Successfully installed cmake-3.27.6 lit-17.0.2 llvmlite-0.41.0 numba-0.58.0 numpy-1.25.2 openai-whisper-20230918 tiktoken-0.3.3 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install moviepy\n",
    "!pip install openai-whisper --no-cache-dir\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGFfud7iN8td",
    "outputId": "e9d60480-7b5b-4947-d7f6-624e055ec124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper model loaded.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import whisper\n",
    "import openai\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# openai 엄지호 api key \n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "# gpt-4-turbo  == gpt-4-1106-preview\n",
    "gpt_model = \"gpt-4-1106-preview\"\n",
    "temperature = 0.3\n",
    "\n",
    "# 모델 로드\n",
    "model = whisper.load_model(\"large\")\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"초를 'HH:MM:SS.mmm' 형태로 변환\"\"\"\n",
    "    return '{:02}:{:02}:{:02}.{:03}'.format(\n",
    "        int(seconds // 3600),\n",
    "        int(seconds % 3600 // 60),\n",
    "        int(seconds % 60),\n",
    "        int((seconds % 1) * 1000)\n",
    "    )\n",
    "\n",
    "def transcribe_audio(audio_file_path, output_directory):\n",
    "    transcribe = model.transcribe(audio=audio_file_path)\n",
    "    segments = transcribe['segments']\n",
    "\n",
    "    # 자막 파일 이름을 포함한 경로 설정\n",
    "    srt_filename = os.path.join(output_directory, \"subtitle_\"+ audio_file_path[-5:-4]+ \".srt\")\n",
    "    with open(srt_filename, 'w', encoding='utf-8') as srt_file:\n",
    "        for idx, segment in enumerate(segments, 1): # srt 세그먼트에 인덱스를 부여하기 위해 enumerate 사용\n",
    "            start_time = format_time(segment['start'])\n",
    "            end_time = format_time(segment['end'])\n",
    "            text = segment['text']\n",
    "            srt_file.write(f\"{idx}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "    \n",
    "    return srt_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 영상 시간만 자르는 함수\n",
    "def extract_times(text):\n",
    "    # 정규 표현식을 사용하여 시간 정보 추출\n",
    "    pattern1 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} --> \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern2 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} - \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern3 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} to \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern4 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} ~ \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    \n",
    "    matches1 = re.findall(pattern1, text)\n",
    "    matches2 = re.findall(pattern2, text)\n",
    "    matches3 = re.findall(pattern3, text)\n",
    "    matches4 = re.findall(pattern4, text)\n",
    "    \n",
    "    match1 = [m1.replace(\" --> \", \"-\") for m1 in matches1]\n",
    "    match2 = [m2.replace(\" - \", \"-\") for m2 in matches2]\n",
    "    match3 = [m3.replace(\" to \", \"-\") for m3 in matches3]\n",
    "    match4 = [m4.replace(\" ~ \", \"-\") for m4 in matches4] \n",
    "    \n",
    "    times = match1 + match2 + match3 + match4\n",
    "    \n",
    "    # times = [t.replace(\" - \", \"-\") for t in match]\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_timeline_list):\n",
    "    if os.path.exists(video_file_path):\n",
    "        filename = \"summerized_subtitle_\" + video_file_path[-5:-4] + \".csv\"\n",
    "        print(f\"파일명 '{filename}'으로 저장됨.\")\n",
    "    else:\n",
    "        filename = \"summerized_subtitle_default.csv\"\n",
    "\n",
    "    # 타임라인만 파일로 만들어서 저장\n",
    "    filename = os.path.join(summerized_subtitle_file_path, filename)\n",
    "    \n",
    "    # 리스트의 모든 항목을 하나의 문자열로 연결하고 작은 따옴표를 제거\n",
    "    csv_timeline = ','.join(summerized_timeline_list).replace('\\'', '')\n",
    "    \n",
    "    # 파일에 저장\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(csv_timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "if9HoORUPSy9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to receive subtitle text and request summarization from GPT\n",
    "def get_summarized_text(text):\n",
    "  messages1 = []\n",
    "  content1 = \"\"\"\n",
    "     The following text is a news subtitle, and I'll provide the time and content of the subtitles.\n",
    "     Then, summarize the entire subtitle content for me.\n",
    "  \"\"\"  + text\n",
    "\n",
    "  completion1 = openai.ChatCompletion.create(\n",
    "      model=gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content1}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response1 = completion1.choices[0].message.content\n",
    "  print(\"Summarizing Subtitle Successful ==================================================\")\n",
    "  print(\"Summarized text\" + chat_response1)\n",
    "  print(\"=========================================================================\")\n",
    "  messages2 = []\n",
    "  content2 = \"\"\"\n",
    "    'first content' is summarized content, and second content is original content with timeline.\n",
    "    Then find first content's content in 'second content' with timeline.\n",
    "    The timeline is stored in the format '\\d{2}:\\d{2}:\\d{2}.\\d{3}'.\n",
    "  \"\"\" + \"\\n\\nfirst content: \" + chat_response1 + \"\"\"\\n\\nNow, find the above information in the following text and match it to the timeline.\\n\\n second content:\"\"\" + text\n",
    "\n",
    "  completion2 = openai.ChatCompletion.create(\n",
    "      model = gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content2}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response2 = completion2.choices[0].message.content\n",
    "  print(\"Matching Timeline Successful ==================================================\")\n",
    "  # Return the summarized and timeline-matched subtitles\n",
    "  return chat_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9LSHPUTWkkU",
    "outputId": "4991810d-5ddd-4561-a1d6-f28dddd01051",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 마지막에 이 함수 하나만 실행하면 모든게 가능하게 만들기 \n",
    "# video_file_path - 비디오 파일이 있는 경로 및 이름 .mp4로 끝나야 함, audio_file_path - 오디오 저장 경로 및 이름 .mp3로 끝나야 함\n",
    "# subtitle_file_path - 생성된 자막 저장할 경로(폴더), summerized_subtitle_file_path - 요약된 자막 저장 경로(폴더)\n",
    "def auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path):\n",
    "    video = VideoFileClip(video_file_path)\n",
    "    # video to audio\n",
    "    ffmpeg_extract_audio(video_file_path, audio_file_path)\n",
    "    print(\"Complete generating audio file\")\n",
    "    # srt subtitles\n",
    "    srt_output = transcribe_audio(audio_file_path, subtitle_file_path)\n",
    "    print(f\"SRT 자막 파일이 생성되었습니다: {srt_output}\")\n",
    "    # SRT 파일 경로 설정\n",
    "    srt_file_path = srt_output\n",
    "    \n",
    "    # SRT 파일 열기\n",
    "    with open(srt_file_path, 'r', encoding='utf-8') as srt_file:\n",
    "        srt_contents = srt_file.read()\n",
    "    \n",
    "    # 생성된 자막 요약 시작 및 타임라인 매칭\n",
    "    summerized_text = get_summarized_text(srt_contents)\n",
    "\n",
    "    # 요약된 자막 및 타임라인 출력\n",
    "    print(\"타임라인에 매칭된 요약된 자막\\n\" + summerized_text)\n",
    "    \n",
    "    # 요약된 자막에서 타임라인만 추출\n",
    "    times = extract_times(summerized_text)\n",
    "    print(\"타임라인만 추출\\n\")\n",
    "    print(times)\n",
    "    # 타임라인 summerized_subtitle_file_path에 저장\n",
    "    save_summerized_timeline(video_file_path, summerized_subtitle_file_path, times)\n",
    "    \n",
    "    # # 추출된 시간 출력\n",
    "    # for start_time, end_time in times:\n",
    "    #     print(f\"Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "    # 2차원 리스트로 추출된 시간 return\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Complete generating audio file\n",
      "SRT 자막 파일이 생성되었습니다: subtitle/subtitle_5.srt\n",
      "Summarizing Subtitle Successful ==================================================\n",
      "Summarized textFrench President Emmanuel Macron, in an exclusive interview with the BBC at the Elysee Palace, has called for Israel to stop its bombing campaign in Gaza, which has resulted in the deaths of civilians, including women and babies. He emphasized that while Israel has the right to defend itself, its response must comply with international rules, the laws of war, and humanitarian law. Macron expressed his belief that a ceasefire would benefit Israel and that the ongoing bombing of civilians in Gaza has no justification or legitimacy.\n",
      "\n",
      "Macron refrained from accusing Israel of war crimes but urged the country to adhere to international law and called for a humanitarian ceasefire. He hopes other world leaders will join him in this call, including those from the US and the UK, who have been more isolated in their stance. The news segment also included a panel discussion with Andrew Fisher, former Director of Policy at the Labour Party under Jeremy Corbyn, and Mo Elasi, Executive Director at the Georgetown Institute of Politics and Public Service, who provided their reactions to Macron's statements.\n",
      "\n",
      "Fisher welcomed Macron's call for a ceasefire and noted that it puts pressure on leaders like President Biden and UK's Rishi Sunak, who have not yet backed a ceasefire. He also pointed out that Macron's comments suggest a recognition that Israel may not be currently abiding by international law, citing the use of white phosphorus and the bombing of civilian areas as illegal actions.\n",
      "\n",
      "Elasi acknowledged the complexity of the situation, with the world torn between supporting Israel's right to self-defense and being horrified by the devastation in Gaza. He mentioned that Hamas is also acting against the interests of the Palestinian people and that international pressure has led to a daily humanitarian pause in the bombing. The Biden administration has been pushing for this, but Elasi believes more steps are needed to protect civilians effectively.\n",
      "\n",
      "In summary, President Macron has called for an immediate halt to the bombing in Gaza and a ceasefire, while recognizing Israel's right to self-defense. He has urged compliance with international law and expressed hope that other world leaders will join his call for a ceasefire. The panelists discussed the significance of Macron's intervention and the broader international response to the conflict.\n",
      "=========================================================================\n",
      "Matching Timeline Successful ==================================================\n",
      "타임라인에 매칭된 요약된 자막\n",
      "The first content's summary can be matched to the timeline in the second content as follows:\n",
      "\n",
      "- Macron's call for Israel to stop its bombing campaign in Gaza: \n",
      "  - \"Israel must stop killing babies and women in Gaza.\" (00:00:00.000 - 00:00:05.500)\n",
      "  - \"We do urge them to stop this bombing in Gaza.\" (00:00:18.100 - 00:00:21.000)\n",
      "\n",
      "- Macron's emphasis on Israel's right to defend itself but within international law:\n",
      "  - \"While recognising Israel's right to protect itself, he said,\" (00:00:14.800 - 00:00:18.100)\n",
      "  - \"But day one, we say that this reaction and the fight against terrorism, because it is led by a democracy, should be compliant with international rules, rule of war and humanitarian international law.\" (00:01:04.000 - 00:01:20.200)\n",
      "\n",
      "- Macron's call for a ceasefire:\n",
      "  - \"I call for a ceasefire and I will urge them for a ceasefire, for a humanitarian ceasefire.\" (00:03:42.000 - 00:03:47.200)\n",
      "\n",
      "- Macron refraining from accusing Israel of war crimes:\n",
      "  - \"Are you saying that Israel is guilty of breaking international humanitarian law, potential war crimes? No, I'm here, look, I think it's not the proper way to approach the question.\" (00:02:45.200 - 00:03:16.000)\n",
      "\n",
      "- Panel discussion with Andrew Fisher and Mo Elasi:\n",
      "  - Andrew Fisher's reaction: (00:03:51.000 - 00:05:34.800)\n",
      "  - Mo Elasi's reaction: (00:05:35.399 - 00:07:38.199)\n",
      "\n",
      "The timeline provided in the second content aligns with the key points from the first content's summary, offering a detailed account of when each aspect of the summary was discussed in the original content.\n",
      "타임라인만 추출\n",
      "\n",
      "['00:00:00.000-00:00:05.500', '00:00:18.100-00:00:21.000', '00:00:14.800-00:00:18.100', '00:01:04.000-00:01:20.200', '00:03:42.000-00:03:47.200', '00:02:45.200-00:03:16.000', '00:03:51.000-00:05:34.800', '00:05:35.399-00:07:38.199']\n",
      "파일명 'summerized_subtitle_5.csv'으로 저장됨.\n",
      "['00:00:00.000-00:00:05.500', '00:00:18.100-00:00:21.000', '00:00:14.800-00:00:18.100', '00:01:04.000-00:01:20.200', '00:03:42.000-00:03:47.200', '00:02:45.200-00:03:16.000', '00:03:51.000-00:05:34.800', '00:05:35.399-00:07:38.199']\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용 예시\n",
    "video_file_path = \"./video/video5.mp4\" # .mp4 파일로 끝나는 path\n",
    "audio_file_path = \"./audio/audio5.mp3\" # .mp3 파일로 끝나는 path\n",
    "subtitle_file_path = \"subtitle\" # 폴더로 끝나는 path\n",
    "summerized_subtitle_file_path = \"summerized_subtitle\" # 폴더로 끝나는 path\n",
    "print(\"================================================\")\n",
    "\n",
    "result_times = auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path)\n",
    "print(result_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 코드 실행할 때마다 이전에 있던 파일 삭제하고 다시 만들기 \n",
    "# -> video1.mp4 -> 1.txt 로 summerized txt 파일 만들기 \n",
    "# TODO: 비디오 길이 n분 이상 안넘어가도록 요약하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브에서 링크로 동영상 다운로드 받는 코드\n",
    "# from pytube import YouTube\n",
    "# DOWNLOAD_FOLDER = \"./\"\n",
    "# url = \"https://www.youtube.com/watch?v=7DbtZY9Kd6Q\"\n",
    "# youtube = YouTube(url)\n",
    "# stream = youtube.streams.get_highest_resolution()\n",
    "# stream.download(DOWNLOAD_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
