{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXFsxhRJHiUI",
    "outputId": "bda36300-ad0e-412b-85c6-00f7488532ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.5)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting triton==2.0.0 (from openai-whisper)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/e7/69/d228b38ffb70858d74538bdfe5aa18c7640b7f07840239690985b3a94009/numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (8.12.0)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
      "Collecting cmake (from triton==2.0.0->openai-whisper)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/72/89/b1cf3cd5fb9f4ae796dd4a743412553f884dad2acbf6b9828d3a0c2b5524/cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper) (3.9.0)\n",
      "Collecting lit (from triton==2.0.0->openai-whisper)\n",
      "  Downloading lit-17.0.2.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/154.6 kB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper)\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/50/df/38c9fb5cc64f4fcc0577a14a0665c2a5de74f45a621ac7708320b1ac80c6/llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper, lit\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=4327352e2dc9142bf945a8833e1e168aa007cc6a3491f2ed27ced1aa5b3562a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.2-py3-none-any.whl size=93257 sha256=90a4c66cc12bb5bac2ba7d0e181110c385bb572b9f646377f77c42e7f9912937\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/3a/ff/73/ce1a12d89231e9ac175fb6493ee1fcc8768e85ee3bea4b98b2\n",
      "Successfully built openai-whisper lit\n",
      "Installing collected packages: lit, cmake, numpy, llvmlite, tiktoken, numba, triton, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "Successfully installed cmake-3.27.6 lit-17.0.2 llvmlite-0.41.0 numba-0.58.0 numpy-1.25.2 openai-whisper-20230918 tiktoken-0.3.3 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install moviepy\n",
    "!pip install openai-whisper --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGFfud7iN8td",
    "outputId": "e9d60480-7b5b-4947-d7f6-624e055ec124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper model loaded.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import whisper\n",
    "import openai\n",
    "\n",
    "# openai 엄지호 api key \n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# 모델 로드\n",
    "model = whisper.load_model(\"medium\")\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "# 가져욜 audio_file_path와 자막을 저장할 output_directory\n",
    "def transcribe_audio(audio_file_path, output_directory):\n",
    "    transcribe = model.transcribe(audio=audio_file_path)\n",
    "    segments = transcribe['segments']\n",
    "\n",
    "    # 경로를 설정하여 자막 파일 이름을 포함합니다.\n",
    "    srt_filename = os.path.join(output_directory, \"output.srt\")  \n",
    "    with open(srt_filename, 'w', encoding='utf-8') as srt_file:\n",
    "        for segment in segments:\n",
    "            start_time = str(timedelta(seconds=int(segment['start'])))\n",
    "            end_time = str(timedelta(seconds=int(segment['end'])))\n",
    "            text = segment['text']\n",
    "            srt_file.write(f\"{start_time} - {end_time}\\n{text}\\n\\n\")\n",
    "\n",
    "    return srt_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 영상 시간만 자르는 함수\n",
    "def extract_times(text):\n",
    "    # 정규 표현식을 사용하여 시간 정보 추출\n",
    "    pattern1 = r'\\d+:\\d+:\\d+ --> \\d+:\\d+:\\d+'\n",
    "    pattern2 = r'\\d+:\\d+:\\d+ - \\d+:\\d+:\\d+'\n",
    "\n",
    "    matches1 = re.findall(pattern1, text)\n",
    "    matches2 = re.findall(pattern2, text)\n",
    "\n",
    "    times = []\n",
    "    times.append(matches1 + matches2)\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# summerized_subtitle_file_path: 생성된 txt 파일을 저장할 directory path, summerized_timeline: 위에서 auto_editing_video의 return 값\n",
    "# 저장 형식은 f\"Start time: {start_time}, End time: {end_time}\\n\"\n",
    "def save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_timeline):\n",
    "    if os.path.exists(video_file_path):\n",
    "        filename = video_file_path[-5:-4] + \".txt\"\n",
    "        print(f\"파일명 '{filename}'으로 저장됨.\")\n",
    "\n",
    "    # 타임라인만 파일로 만들어서 저장\n",
    "    filename = os.path.join(summerized_subtitle_file_path , filename)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(summerized_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "if9HoORUPSy9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "temperature = 0.3\n",
    "\n",
    "# text로 생성된 자막 받아와서 GPT에 요약 요청하는 함수\n",
    "def get_summerize_text(text):\n",
    "  messages1 = []\n",
    "  content1 = \"\"\"\n",
    "     다음 글은 시사뉴스 자막인데 자막이 진행되는 시간과 자막 내용을 줄거야.\n",
    "     그러면 너는 먼저 자막 내용을 요약해줘\n",
    "  \"\"\"  + text\n",
    "\n",
    "  completion1 = openai.ChatCompletion.create(\n",
    "      model=gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content1}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response1 = completion1.choices[0].message.content\n",
    "  print(\"==================================================\")\n",
    "\n",
    "  messages2 = []\n",
    "  content2 = \"\"\"\n",
    "    내가 첫 번째로 요약된 내용의 글을 줄거야 그러면 너는 2번째로 받은 글에서 요약된 내용을 찾아서 자막 타임라인을 알려줘. \n",
    "    몇 분 몇 초부터 몇 분 몇 초인지 알려주고 총 요약된 글은 1000자 이내로 요약해줘.\n",
    "  \"\"\" + chat_response1 + \"\"\"다음 글에서 위의 내용을 찾아서 타임라인에 매칭시켜줘.\"\"\" + text\n",
    "  completion2 = openai.ChatCompletion.create(\n",
    "      model = gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content2}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response2 = completion2.choices[0].message.content\n",
    "  # 요약되고 타임라인 매칭된 자막 return\n",
    "  return chat_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9LSHPUTWkkU",
    "outputId": "4991810d-5ddd-4561-a1d6-f28dddd01051",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 마지막에 이 함수 하나만 실행하면 모든게 가능하게 만들기 \n",
    "# video_file_path - 비디오 파일이 있는 경로 및 이름 .mp4로 끝나야 함, audio_file_path - 오디오 저장 경로 및 이름 .mp3로 끝나야 함\n",
    "# subtitle_file_path - 생성된 자막 저장할 경로(폴더), summerized_subtitle_file_path - 요약된 자막 저장 경로(폴더)\n",
    "def auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path):\n",
    "    video = VideoFileClip(video_file_path)\n",
    "    # video to audio\n",
    "    ffmpeg_extract_audio(video_file_path, audio_file_path)\n",
    "    # srt subtitles\n",
    "    srt_output = transcribe_audio(audio_file_path, subtitle_file_path)\n",
    "    print(f\"SRT 자막 파일이 생성되었습니다: {srt_output}\")\n",
    "    # SRT 파일 경로 설정\n",
    "    srt_file_path = srt_output\n",
    "    \n",
    "    # SRT 파일 열기\n",
    "    with open(srt_file_path, 'r', encoding='utf-8') as srt_file:\n",
    "        srt_contents = srt_file.read()\n",
    "    \n",
    "    # 생성된 자막 요약 시작 및 타임라인 매칭\n",
    "    summerized_text = get_summerize_text(srt_contents)\n",
    "\n",
    "    # 요약된 자막 summerized_subtitle_file_path에 저장\n",
    "    save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_text)\n",
    "    \n",
    "    # 요약된 자막 및 타임라인 출력\n",
    "    print(summerized_text)\n",
    "    \n",
    "    # 요약된 자막에서 타임라인만 추출\n",
    "    times = extract_times(summerized_text)\n",
    "    \n",
    "    # # 추출된 시간 출력\n",
    "    # for start_time, end_time in times:\n",
    "    #     print(f\"Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "    # 2차원 리스트로 추출된 시간 return\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "SRT 자막 파일이 생성되었습니다: ./subtitle/output.srt\n",
      "파일명 '1.txt'으로 저장됨.\n",
      "0:00:00 - 0:00:04: 요즘 10대, 10대들 같은 경우는 초점성이 없어요.\n",
      "0:00:04 - 0:00:07: 그냥 파티를 하죠, 그냥 이제.\n",
      "0:00:07 - 0:00:17: 여기다 되게 마약이라고 하면 멋있어 보이고 아니면 되게 특이해 보이고 하니까 그냥 거부감 없이 많이들 복용하는 편이고.\n",
      "0:00:17 - 0:00:19: 이게 위험한지도 몰라요.\n",
      "0:00:19 - 0:00:27: 본인들 그냥 더 기분 좋고 더 재밌게 놀기 위해서 많이들 하는 편이고.\n",
      "0:00:28 - 0:00:36: 뿌리는 경우도 많고 그냥 약을 가지고 있다가 이거를 중독시켜서 나중에 찾아볼까 하기 위해서 그냥 공짜로 뿌려요, 많이.\n",
      "0:00:37 - 0:00:43: 19살에서 20살에 지나가는 해, 1월 1일 날 클럽을 먼저 가보고 싶었어요.\n",
      "0:00:43 - 0:00:49: 그래서 클럽을 갔는데 어떤 정말 처음 본 남성분께서 도는 교중에 먼저 얘기를 꺼내시더라고요.\n",
      "0:00:49 - 0:00:59: 아니야 그게 뭐냐고 했더니 피우는 건데 대마초라고도 하고 이거 피우면 되게 기분 좋아진다, 좋다고 얘기를 하셔서.\n",
      "0:00:59 - 0:01:05: 마약이라는 거를 알고는 있었는데 궁금해서 같이 따라가게 돼서 취향을 배치하게 됐죠.\n",
      "0:01:07 - 0:01:10: 요즘 클럽에 가면 그런 게 거의 일상인가요?\n",
      "0:01:10 - 0:01:12: 옛날부터 심해졌어요.\n",
      "0:01:12 - 0:01:18: 요즘에는 진짜 클럽이 홍대나 이태원 한 바퀴만 돌아도.\n",
      "0:01:18 - 0:01:22: 한 번 시작한 마약은 다른 마약으로 점점 범위를 넓혔습니다.\n",
      "0:01:25 - 0:01:36: 대마초를 하고 나서 LSD를 같이 해보고 액상대마도 같이 해보고 엑스터시를 보게 되면 기분이 되게 업이 돼서 음악이랑 같이 어울려져서 좋아요 기분이.\n",
      "0:01:36 - 0:01:44: 그래서 엑스터시도 하고 그때 뭐 몰리라는 약도 하고, 케타민이라는 것도 하고 다양한 걸 한 것 같아요.\n",
      "0:01:44 - 0:01:51: 웬만한 알약 종류나 그런 향정신성 마약, 신종 마약 그런 것들은 다 해본 것 같아요.\n",
      "0:01:51 - 0:01:57: 근데 전 여자다 보니까 그분은 남자고 어쩌면 성방기를 좀 오르잖아요.\n",
      "0:01:57 - 0:01:59: 그래서 공짜로 약을 주신 것 같아요.\n",
      "0:02:03 - 0:02:07: 공짜 마약이 끊기자 스스로 마약을 구하기 시작했습니다.\n",
      "0:02:07 - 0:02:14: 그리고 병원에서 구할 수 있는 향정신성 의약품 펜타닐에 빠져들었습니다.\n",
      "0:02:38 - 0:02:44: 그냥 그거예요. 병원 의사가 딜러고 약국이 중간 판매책이고 저희가 그걸 사는 거예요.\n",
      "0:02:44 - 0:02:50: 병원 같은 경우에는 정말 그냥 다 쓰러져나가는 병원 있잖아요.\n",
      "0:02:50 - 0:02:55: 동네 병원, 작은 병원, 나이가 많은 의사가 있는 병원.\n",
      "0:02:55 - 0:03:00: 딱 봤을 때 여기 사이즈 나오겠는데 이런 병원을 주로 찾아가는 편이에요.\n",
      "0:03:00 - 0:03:02: 다 살리면 손에 쩐다. 다 다치잖아.\n",
      "0:03:02 - 0:03:07: 그렇죠. 근데 그 병원 리스트도 공유를 하는 편이에요. 돈을 주고.\n",
      "0:03:07 - 0:03:10: 그리고 한 병원은 그냥 알면서도 주는 경우가 많아요.\n",
      "0:03:10 - 0:03:14: 그냥 들어가자마자 병원사가 물어봐요. 했지? 이렇게 물어봐요.\n",
      "0:03:14 - 0:03:18: 그럼 네 맞아요 앉아 계세요. 이런 병원도 있었어요.\n",
      "0:03:21 - 0:03:25: 여성은 친구 상당수가 마약을 하고 있다고 말했습니다.\n",
      "0:03:26 - 0:03:33: 주변에 이렇게 친구분들 보면 약을 좀 사는 분들이 많으신가요?\n",
      "0:03:33 - 0:03:36: 네 지금 되게 엄청 많은 편이고 더 늘고 있어요.\n",
      "0:03:36 - 0:03:44: 그리고 원래는 하지 않았는데 하게 되는 친구들도 많고 자기 이제 약한다고 치는 경우가 많잖아요.\n",
      "0:03:44 - 0:03:50: 이런 거 해 봐. 어린 친구들 같은 경우에 이런 것도 하고 저것도 하고 이것도 해.\n",
      "0:03:50 - 0:03:56: 이렇게 말이 많은 친구들은 피하는 편이고 조심스럽게 하는 친구들한테 주로 찾아가는 편이죠.\n",
      "0:03:56 - 0:04:04: 같이 하는 거 하고 싶어 하고 구매도 좀 하고 싶어 하니까 다 이제 진단을 딱 봐요.\n",
      "0:04:04 - 0:04:09: 이 친구가 괜찮은 친구인지 아니면 뭐 위험한 친구인지.\n",
      "0:04:09 - 0:04:15: 펜타닐을 저 친구가 해. 이 친구가 해. 이러면 같이 불러서 펜타닐을 좀 한다든지\n",
      "0:04:15 - 0:04:23: 아니면 본인이 필요하니까 없을 때 이제 데뷔해서 좀 알아준다든지 이런 식으로 꼬리를 물고 자꾸.\n",
      "0:04:23 - 0:04:29: 인맥을 쌓아가는 편이죠. 저가 알기만 하던 동생이 굉장히 평범한 친구거든요.\n",
      "0:04:29 - 0:04:35: 평범하게 회사 다니고 그냥 일하고 자기 하고 싶은 거 하고 그런 친구였는데\n",
      "0:04:35 - 0:04:43: 그 친구가 제가 중급자였으니까 갑자기 어제 전화가 오더라고요. 본인이 필요뿐을 시작하게 되었는데\n",
      "0:04:43 - 0:04:49: 금단이 있다고 어떻게 이거를 하면 금단이 일어날 수 있냐 이런 식으로 질문을 하더라고요.\n",
      "0:04:49 - 0:04:56: 좀 많이 들었죠. 그 친구가 나이가 한지 21살? 22? 정도밖에 안 되는 친구였거든요.\n",
      "0:04:59 - 0:05:03: 필로폰 투약 혐의로 수감돼 지난해 출소한 40대 남성은\n",
      "0:05:03 - 0:05:09: 마약 중독자들이 보기에도 최근 젊은이들의 마약 실패가 위험하다고 말합니다.\n",
      "0:05:10 - 0:05:16: 저희 때는 그게 구하기 힘들 때는 정말 며칠씩 기다려야 될 때도 있고\n",
      "0:05:16 - 0:05:25: 지금은 인터널만 하지 않으면 아이들은 컴퓨터로 인터넷 상에서 도마 갖고 있으면 나이를 보려고 하는 학우들은\n",
      "0:05:25 - 0:05:30: 한 시간 안에는 그 자리에서 받아볼 수 있으니까 그렇게 시대가 변한 거죠.\n",
      "0:05:30 - 0:05:35: 지혜인 줄은 몰라요. 해외 유학을 갔다 온 친구들이 많더라고요.\n",
      "0:05:35 - 0:05:43: 그래서 미국에 군부하러 가서 거기서 이제 배만은 거의 합법적인 수준으로 하니까 한국의 법이 왜 이러냐.\n",
      "0:05:43 - 0:05:49: 그러면 다시 미국 나가서 살아야 되겠다. 그 이유는 이제 거기서 합법적으로 마약을 할 수 있으니까.\n",
      "0:05:49 - 0:05:51: 그런 답이 대부분.\n",
      "0:05:51 - 0:05:57: 그런데 미국에서 온 친구들은 이제 그거는 이제 자기네가 자기네 합리화시키느라고 하는 거고\n",
      "0:05:57 - 0:06:01: 약물을 굉장히 우리보다 더하게 어린 나이에 경험을 많이 했어요.\n",
      "0:06:02 - 0:06:08: 펜타닐부터 시장에서 해로인 코카앤까지 경험을 하고 오는 친구들이 있는데\n",
      "0:06:08 - 0:06:17: 그 중에 이제 배마가 가장 또 자기한테 잘 맞고 그리고 이제 한국에 와서는 해로인이나 코카앤 구하기가 미국만큼 수월하기가 아닙니까.\n",
      "0:06:24 - 0:06:28: 약을 못 구하잖아요. 그러면 그때부터 미치는 거예요.\n",
      "0:06:28 - 0:06:33: 내가 이제 약이 다 떨어져 가는데 금단 10시간이에요. 12시간 지났어요.\n",
      "0:06:33 - 0:06:41: 그러면 아, 이거를 참아보고 끊어볼까 이게 아니라 당장 구해야 돼. 병원에 전국을 다니는 거야.\n",
      "0:06:41 - 0:06:47: 마약 중독자들의 말로는 정말 쎄쎄하거든요.\n",
      "0:06:47 - 0:06:54: 모든 걸 잃게 돼요. 자족도 잃고 친구도 잃고 애인도 잃고 그냥 모든 걸 다 잃어요.\n",
      "0:06:58 - 0:07:06: 그런 게 마지막 길 아니면 교통소를 가거나 마지막에는 정신경험을 가거나 그게 딱 맞는 바인 것 같아요.\n",
      "0:07:06 - 0:07:15: 그리고 그걸 몸으로 배워서 내가 느낄 때쯤 되면 그때는 인생은 다 허비하고 나면 수가 아니에요.\n",
      "[['0:00:00 - 0:00:04', '0:00:04 - 0:00:07', '0:00:07 - 0:00:17', '0:00:17 - 0:00:19', '0:00:19 - 0:00:27', '0:00:28 - 0:00:36', '0:00:37 - 0:00:43', '0:00:43 - 0:00:49', '0:00:49 - 0:00:59', '0:00:59 - 0:01:05', '0:01:07 - 0:01:10', '0:01:10 - 0:01:12', '0:01:12 - 0:01:18', '0:01:18 - 0:01:22', '0:01:25 - 0:01:36', '0:01:36 - 0:01:44', '0:01:44 - 0:01:51', '0:01:51 - 0:01:57', '0:01:57 - 0:01:59', '0:02:03 - 0:02:07', '0:02:07 - 0:02:14', '0:02:38 - 0:02:44', '0:02:44 - 0:02:50', '0:02:50 - 0:02:55', '0:02:55 - 0:03:00', '0:03:00 - 0:03:02', '0:03:02 - 0:03:07', '0:03:07 - 0:03:10', '0:03:10 - 0:03:14', '0:03:14 - 0:03:18', '0:03:21 - 0:03:25', '0:03:26 - 0:03:33', '0:03:33 - 0:03:36', '0:03:36 - 0:03:44', '0:03:44 - 0:03:50', '0:03:50 - 0:03:56', '0:03:56 - 0:04:04', '0:04:04 - 0:04:09', '0:04:09 - 0:04:15', '0:04:15 - 0:04:23', '0:04:23 - 0:04:29', '0:04:29 - 0:04:35', '0:04:35 - 0:04:43', '0:04:43 - 0:04:49', '0:04:49 - 0:04:56', '0:04:59 - 0:05:03', '0:05:03 - 0:05:09', '0:05:10 - 0:05:16', '0:05:16 - 0:05:25', '0:05:25 - 0:05:30', '0:05:30 - 0:05:35', '0:05:35 - 0:05:43', '0:05:43 - 0:05:49', '0:05:49 - 0:05:51', '0:05:51 - 0:05:57', '0:05:57 - 0:06:01', '0:06:02 - 0:06:08', '0:06:08 - 0:06:17', '0:06:24 - 0:06:28', '0:06:28 - 0:06:33', '0:06:33 - 0:06:41', '0:06:41 - 0:06:47', '0:06:47 - 0:06:54', '0:06:58 - 0:07:06', '0:07:06 - 0:07:15']]\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용 예시\n",
    "video_file_path = \"./video/video1.mp4\"\n",
    "audio_file_path = \"./audio/audio1.mp3\"\n",
    "subtitle_file_path = \"./subtitle\"\n",
    "summerized_subtitle_file_path = \"./summerized_subtitle\"\n",
    "print(\"================================================\")\n",
    "# 타임라인만 표시된 2차원 리스트가 result_times에 저장됨 -> 가끔 GPT에서 요약을 잘못하면 타임라인 생성이 안됨 -> 개선 필요\n",
    "result_times = auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path)\n",
    "print(result_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "temperature = 0.3\n",
    "\n",
    "with open(\"./subtitle/output.srt\", 'r', encoding='utf-8') as srt_file:\n",
    "    srt_contents = srt_file.read()\n",
    "\n",
    "messages1 = []\n",
    "content1 = \"\"\"\n",
    "    다음 글은 시사뉴스 자막인데 자막이 진행되는 시간과 자막 내용을 줄거야.\n",
    "    그러면 너는 먼저 자막 내용을 요약해줘.\n",
    "\"\"\"  + srt_contents\n",
    "\n",
    "completion1 = openai.ChatCompletion.create(\n",
    "    model=gpt_model,\n",
    "    messages = [\n",
    "      {\"role\":\"user\", \"content\": content1}\n",
    "    ],\n",
    "    temperature = temperature\n",
    ")\n",
    "chat_response1 = completion1.choices[0].message.content\n",
    "print(\"==================================================\")\n",
    "\n",
    "messages2 = []\n",
    "content2 = \"\"\"\n",
    "내가 첫 번째로 요약된 내용의 글을 줄거야 그러면 너는 2번째로 받은 글에서 요약된 내용을 찾아서 자막 타임라인을 알려줘. \n",
    "몇 분 몇 초부터 몇 분 몇 초인지 알려줘.\\n\n",
    "\"\"\" + chat_response1 + \"\"\"\\n\\n다음 글에서 위의 내용을 찾아서 타임라인에 매칭시켜줘. 대신 타임라인 모든 시간을 더한 것이 5분 이하로 나오게 해 줘.\\n\\n\"\"\" + srt_contents\n",
    "completion2 = openai.ChatCompletion.create(\n",
    "    model = gpt_model,\n",
    "    messages = [\n",
    "      {\"role\":\"user\", \"content\": content2}\n",
    "    ],\n",
    "    temperature = temperature\n",
    ")\n",
    "chat_response2 = completion2.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 - 0:00:04\n",
      "요즘 10대들은 초점성이 없고 파티를 즐기기 위해 마약을 복용하는 경향이 있다.\n",
      "\n",
      "0:00:19 - 0:00:27\n",
      "마약 중독자들은 다양한 종류의 마약을 시도하며, 병원에서 향정신성 의약품을 구하고 있다.\n",
      "\n",
      "0:00:37 - 0:00:43\n",
      "마약을 하는 친구들이 많아지고 있으며, 친구들 사이에서 마약을 공유하고 함께 사용하는 경우가 많다.\n",
      "\n",
      "0:01:07 - 0:01:10\n",
      "마약 실패는 젊은이들에게 위험하며, 마약을 구하기가 쉬워져 젊은이들의 중독 가능성이 높아졌다.\n",
      "\n",
      "0:01:51 - 0:01:57\n",
      "해외에서 유학한 친구들은 마약을 합법적으로 사용할 수 있는 나라로 돌아가고 싶어한다.\n",
      "\n",
      "0:02:03 - 0:02:07\n",
      "마약 중독자들은 모든 것을 잃게 되며, 마약을 구하기 위해 병원을 전국적으로 돌아다니는 경우도 있다.\n",
      "\n",
      "0:03:21 - 0:03:25\n",
      "여성은 친구 상당수가 마약을 하고 있다고 말했습니다.\n",
      "\n",
      "0:03:33 - 0:03:36\n",
      "네 지금 되게 엄청 많은 편이고 더 늘고 있어요.\n",
      "\n",
      "0:04:09 - 0:04:15\n",
      "이 친구가 괜찮은 친구인지 아니면 뭐 위험한 친구인지.\n",
      "\n",
      "0:05:03 - 0:05:09\n",
      "지금은 인터널만 하지 않으면 아이들은 컴퓨터로 인터넷 상에서 도마 갖고 있으면 나이를 보려고 하는 학우들은\n",
      "\n",
      "0:05:35 - 0:05:43\n",
      "그래서 미국에 군부하러 가서 거기서 이제 배만은 거의 합법적인 수준으로 하니까 한국의 법이 왜 이러냐.\n",
      "\n",
      "0:06:24 - 0:06:28\n",
      "약을 못 구하잖아요. 그러면 그때부터 미치는 거예요.\n",
      "\n",
      "0:06:58 - 0:07:06\n",
      "그런 게 마지막 길 아니면 교통소를 가거나 마지막에는 정신경험을 가거나 그게 딱 맞는 바인 것 같아요.\n"
     ]
    }
   ],
   "source": [
    "print(chat_response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "temperature = 0.3\n",
    "\n",
    "with open(\"./subtitle/output.srt\", 'r', encoding='utf-8') as srt_file:\n",
    "    srt_contents = srt_file.read()\n",
    "\n",
    "messages1 = []\n",
    "content1 = \"\"\"\n",
    "    다음 글은 시사뉴스 자막인데 자막이 진행되는 시간과 자막 내용을 줄거야.\n",
    "    그러면 너는 먼저 자막 내용을 요약해줘.\n",
    "\"\"\"  + srt_contents\n",
    "\n",
    "completion1 = openai.ChatCompletion.create(\n",
    "    model=gpt_model,\n",
    "    messages = [\n",
    "      {\"role\":\"user\", \"content\": content1}\n",
    "    ],\n",
    "    temperature = temperature\n",
    ")\n",
    "chat_response1 = completion1.choices[0].message.content\n",
    "print(\"==================================================\")\n",
    "\n",
    "messages2 = []\n",
    "content2 = \"\"\"\n",
    "내가 첫 번째로 요약된 내용의 글을 줄거야 그러면 너는 2번째로 받은 글에서 요약된 내용을 찾아서 자막 타임라인을 알려줘. \n",
    "몇 분 몇 초부터 몇 분 몇 초인지 알려줘.\\n\n",
    "\"\"\" + chat_response1 + \"\"\"\\n\\n다음 글에서 위의 내용을 찾아서 타임라인에 매칭시켜줘. 대신 타임라인 모든 시간을 더한 것이 5분 이하로 나오게 해 줘.\\n\\n\"\"\" + srt_contents\n",
    "completion2 = openai.ChatCompletion.create(\n",
    "    model = gpt_model,\n",
    "    messages = [\n",
    "      {\"role\":\"user\", \"content\": content2}\n",
    "    ],\n",
    "    temperature = temperature\n",
    ")\n",
    "chat_response2 = completion2.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 코드 실행할 때마다 이전에 있던 파일 삭제하고 다시 만들기 \n",
    "# -> video1.mp4 -> 1.txt 로 summerized txt 파일 만들기 \n",
    "# TODO: 비디오 길이 n분 이상 안넘어가도록 요약하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Back Up\n",
    "\n",
    "\n",
    "# # video file path 환경에 맞게 설정\n",
    "# video_file_path = \"drive/MyDrive/content/video1.mp4\"\n",
    "# video = VideoFileClip(video_file_path)\n",
    "# # audio file path 환경에 맞게 설정\n",
    "# audio_file_path = \"drive/MyDrive/content/audio1.mp3\"\n",
    "# # video.audio.write_audiofile(audio_file_path)\n",
    "\n",
    "# # 비디오에서 오디오를 추출하고 .mp3 파일로 저장 (video_file_path에 있는 .mp4 파일을 audio_file_path에 .mp3로 저장)\n",
    "# ffmpeg_extract_audio(video_file_path, audio_file_path)\n",
    "\n",
    "# output_directory = \"drive/MyDrive/content/SrtFiles\"  # 저장할 디렉터리 경로를 설정합니다.\n",
    "# srt_output = transcribe_audio(audio_file_path, output_directory)\n",
    "# print(f\"SRT 자막 파일이 생성되었습니다: {srt_output}\")\n",
    "\n",
    "\n",
    "# # SRT 파일 경로 설정\n",
    "# srt_file_path = srt_output\n",
    "\n",
    "# # SRT 파일 열기\n",
    "# with open(srt_file_path, 'r', encoding='utf-8') as srt_file:\n",
    "#     srt_contents = srt_file.read()\n",
    "\n",
    "# # 파일 내용 출력\n",
    "# print(srt_contents)\n",
    "\n",
    "# # GPT 3.5 turbo 16k 사용\n",
    "# response = get_summerize_text(srt_contents)\n",
    "# # GPT 요약 후 자막 시간 매칭 결과\n",
    "# # print(response)\n",
    "\n",
    "# # 시간 추출 함수 호출\n",
    "# # times = extract_times(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브에서 링크로 동영상 다운로드 받는 코드\n",
    "# from pytube import YouTube\n",
    "# DOWNLOAD_FOLDER = \"./\"\n",
    "# url = \"https://www.youtube.com/watch?v=7DbtZY9Kd6Q\"\n",
    "# youtube = YouTube(url)\n",
    "# stream = youtube.streams.get_highest_resolution()\n",
    "# stream.download(DOWNLOAD_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
