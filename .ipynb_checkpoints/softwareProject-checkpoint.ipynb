{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXFsxhRJHiUI",
    "outputId": "bda36300-ad0e-412b-85c6-00f7488532ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.5)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting triton==2.0.0 (from openai-whisper)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/e7/69/d228b38ffb70858d74538bdfe5aa18c7640b7f07840239690985b3a94009/numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (8.12.0)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
      "Collecting cmake (from triton==2.0.0->openai-whisper)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/72/89/b1cf3cd5fb9f4ae796dd4a743412553f884dad2acbf6b9828d3a0c2b5524/cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper) (3.9.0)\n",
      "Collecting lit (from triton==2.0.0->openai-whisper)\n",
      "  Downloading lit-17.0.2.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/154.6 kB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper)\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/50/df/38c9fb5cc64f4fcc0577a14a0665c2a5de74f45a621ac7708320b1ac80c6/llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper, lit\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=4327352e2dc9142bf945a8833e1e168aa007cc6a3491f2ed27ced1aa5b3562a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.2-py3-none-any.whl size=93257 sha256=90a4c66cc12bb5bac2ba7d0e181110c385bb572b9f646377f77c42e7f9912937\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/3a/ff/73/ce1a12d89231e9ac175fb6493ee1fcc8768e85ee3bea4b98b2\n",
      "Successfully built openai-whisper lit\n",
      "Installing collected packages: lit, cmake, numpy, llvmlite, tiktoken, numba, triton, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "Successfully installed cmake-3.27.6 lit-17.0.2 llvmlite-0.41.0 numba-0.58.0 numpy-1.25.2 openai-whisper-20230918 tiktoken-0.3.3 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install moviepy\n",
    "!pip install openai-whisper --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGFfud7iN8td",
    "outputId": "e9d60480-7b5b-4947-d7f6-624e055ec124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper model loaded.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import whisper\n",
    "import openai\n",
    "\n",
    "# openai 엄지호 api key \n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# 모델 로드\n",
    "model = whisper.load_model(\"medium\")\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "# 가져욜 audio_file_path와 자막을 저장할 output_directory\n",
    "def transcribe_audio(audio_file_path, output_directory):\n",
    "    transcribe = model.transcribe(audio=audio_file_path)\n",
    "    segments = transcribe['segments']\n",
    "\n",
    "    # 경로를 설정하여 자막 파일 이름을 포함합니다.\n",
    "    srt_filename = os.path.join(output_directory, \"subtitle_\"+ audio_file_path[-5:-4]+ \".srt\")\n",
    "    with open(srt_filename, 'w', encoding='utf-8') as srt_file:\n",
    "        for segment in segments:\n",
    "            start_time = str(timedelta(seconds=int(segment['start'])))\n",
    "            end_time = str(timedelta(seconds=int(segment['end'])))\n",
    "            text = segment['text']\n",
    "            srt_file.write(f\"{start_time} - {end_time}\\n{text}\\n\\n\")\n",
    "\n",
    "    return srt_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 영상 시간만 자르는 함수\n",
    "def extract_times(text):\n",
    "    # 정규 표현식을 사용하여 시간 정보 추출\n",
    "    pattern1 = r'\\d+:\\d+:\\d+ --> \\d+:\\d+:\\d+'\n",
    "    pattern2 = r'\\d+:\\d+:\\d+ - \\d+:\\d+:\\d+'\n",
    "\n",
    "    matches1 = re.findall(pattern1, text)\n",
    "    matches2 = re.findall(pattern2, text)\n",
    "    match = matches1 + matches2\n",
    "    \n",
    "    times = [t.replace(\" - \", \"-\") for t in match]\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# summerized_subtitle_file_path: 생성된 txt 파일을 저장할 directory path, summerized_timeline: 위에서 auto_editing_video의 return 값\n",
    "# 저장 형식은 f\"Start time: {start_time}, End time: {end_time}\\n\"\n",
    "def save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_timeline):\n",
    "    if os.path.exists(video_file_path):\n",
    "        filename = \"summerized_subtitle_\" + video_file_path[-5:-4] + \".txt\"\n",
    "        print(f\"파일명 '{filename}'으로 저장됨.\")\n",
    "\n",
    "    # 타임라인만 파일로 만들어서 저장\n",
    "    filename = os.path.join(summerized_subtitle_file_path , filename)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(summerized_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "if9HoORUPSy9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "temperature = 0.3\n",
    "\n",
    "# text로 생성된 자막 받아와서 GPT에 요약 요청하는 함수\n",
    "def get_summerize_text(text):\n",
    "  messages1 = []\n",
    "  content1 = \"\"\"\n",
    "     다음 글은 시사뉴스 자막인데 자막이 진행되는 시간과 자막 내용을 줄거야.\n",
    "     그러면 너는 전체 자막 내용을 요약해줘\n",
    "  \"\"\"  + text\n",
    "\n",
    "  completion1 = openai.ChatCompletion.create(\n",
    "      model=gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content1}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response1 = completion1.choices[0].message.content\n",
    "  print(\"Sumerizing Subtitle Succesful ==================================================\")\n",
    "\n",
    "  messages2 = []\n",
    "  content2 = \"\"\"\n",
    "    내가 첫 번째로 요약된 내용의 글을 줄거야 그러면 너는 2번째로 받은 글에서 요약된 내용을 찾아서 자막 타임라인을 알려줘. \n",
    "    몇 분 몇 초부터 몇 분 몇 초인지 알려줘. \n",
    "  \"\"\" + chat_response1 + \"\"\"다음 글에서 위의 내용을 찾아서 타임라인에 매칭시켜줘.\"\"\" + text\n",
    "\n",
    "    \n",
    "  completion2 = openai.ChatCompletion.create(\n",
    "      model = gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content2}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response2 = completion2.choices[0].message.content\n",
    "  print(\"Matching Timeline Succesful ==================================================\")\n",
    "  # 요약되고 타임라인 매칭된 자막 return\n",
    "  return chat_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9LSHPUTWkkU",
    "outputId": "4991810d-5ddd-4561-a1d6-f28dddd01051",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 마지막에 이 함수 하나만 실행하면 모든게 가능하게 만들기 \n",
    "# video_file_path - 비디오 파일이 있는 경로 및 이름 .mp4로 끝나야 함, audio_file_path - 오디오 저장 경로 및 이름 .mp3로 끝나야 함\n",
    "# subtitle_file_path - 생성된 자막 저장할 경로(폴더), summerized_subtitle_file_path - 요약된 자막 저장 경로(폴더)\n",
    "def auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path):\n",
    "    video = VideoFileClip(video_file_path)\n",
    "    # video to audio\n",
    "    ffmpeg_extract_audio(video_file_path, audio_file_path)\n",
    "    # srt subtitles\n",
    "    srt_output = transcribe_audio(audio_file_path, subtitle_file_path)\n",
    "    print(f\"SRT 자막 파일이 생성되었습니다: {srt_output}\")\n",
    "    # SRT 파일 경로 설정\n",
    "    srt_file_path = srt_output\n",
    "    \n",
    "    # SRT 파일 열기\n",
    "    with open(srt_file_path, 'r', encoding='utf-8') as srt_file:\n",
    "        srt_contents = srt_file.read()\n",
    "    \n",
    "    # 생성된 자막 요약 시작 및 타임라인 매칭\n",
    "    summerized_text = get_summerize_text(srt_contents)\n",
    "\n",
    "    # 요약된 자막 summerized_subtitle_file_path에 저장\n",
    "    save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_text)\n",
    "    \n",
    "    # 요약된 자막 및 타임라인 출력\n",
    "    print(summerized_text)\n",
    "    \n",
    "    # 요약된 자막에서 타임라인만 추출\n",
    "    times = extract_times(summerized_text)\n",
    "    \n",
    "    # # 추출된 시간 출력\n",
    "    # for start_time, end_time in times:\n",
    "    #     print(f\"Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "    # 2차원 리스트로 추출된 시간 return\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "SRT 자막 파일이 생성되었습니다: ./subtitle/subtitle_2.srt\n",
      "Sumerizing Subtitle Succesful ==================================================\n",
      "Matching Timeline Succesful ==================================================\n",
      "파일명 'summerized_subtitle_2.txt'으로 저장됨.\n",
      "요약된 내용의 타임라인은 다음과 같습니다:\n",
      "\n",
      "- 0:00:00 - 0:00:07: 한국의 합계출산율이 전 세계에서 가장 낮음\n",
      "- 0:00:07 - 0:00:13: 인구 절벽으로 국가 소멸 경고\n",
      "- 0:00:13 - 0:00:22: 인구 감소에 따른 아파트 가격 하락 예상\n",
      "- 0:01:46 - 0:01:55: 1인 가구 증가로 주택 수요 늘어남\n",
      "- 0:02:22 - 0:02:31: 수도권 집값 계속 상승\n",
      "- 0:02:55 - 0:03:04: 지방에서도 좋은 일자리와 학군이 밀집된 지역, 브랜드 아파트 가격 상승\n",
      "- 0:03:14 - 0:03:21: 청년들이 결혼과 출산을 망설임\n",
      "- 0:03:37 - 0:03:45: 정부의 다양한 혜택에도 불구하고 신혼부부 임대주택 계약률 저조\n",
      "- 0:04:02 - 0:04:09: 부동산 버블 붕괴와 저출산으로 인한 인구 감소가 맞물려 장기 불황 우려\n",
      "\n",
      "['0:00:00-0:00:07', '0:00:07-0:00:13', '0:00:13-0:00:22', '0:01:46-0:01:55', '0:02:22-0:02:31', '0:02:55-0:03:04', '0:03:14-0:03:21', '0:03:37-0:03:45', '0:04:02-0:04:09']\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용 예시\n",
    "video_file_path = \"./video/video2.mp4\" # .mp4 파일로 끝나는 path\n",
    "audio_file_path = \"./audio/audio2.mp3\" # .mp3 파일로 끝나는 path\n",
    "subtitle_file_path = \"./subtitle\" # 폴더로 끝나는 path\n",
    "summerized_subtitle_file_path = \"./summerized_subtitle\" # 폴더로 끝나는 path\n",
    "print(\"================================================\")\n",
    "\n",
    "result_times = auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path)\n",
    "print(result_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 코드 실행할 때마다 이전에 있던 파일 삭제하고 다시 만들기 \n",
    "# -> video1.mp4 -> 1.txt 로 summerized txt 파일 만들기 \n",
    "# TODO: 비디오 길이 n분 이상 안넘어가도록 요약하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브에서 링크로 동영상 다운로드 받는 코드\n",
    "# from pytube import YouTube\n",
    "# DOWNLOAD_FOLDER = \"./\"\n",
    "# url = \"https://www.youtube.com/watch?v=7DbtZY9Kd6Q\"\n",
    "# youtube = YouTube(url)\n",
    "# stream = youtube.streams.get_highest_resolution()\n",
    "# stream.download(DOWNLOAD_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
