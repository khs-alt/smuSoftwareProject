{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXFsxhRJHiUI",
    "outputId": "bda36300-ad0e-412b-85c6-00f7488532ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.5)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting triton==2.0.0 (from openai-whisper)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/e7/69/d228b38ffb70858d74538bdfe5aa18c7640b7f07840239690985b3a94009/numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (8.12.0)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
      "Collecting cmake (from triton==2.0.0->openai-whisper)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/72/89/b1cf3cd5fb9f4ae796dd4a743412553f884dad2acbf6b9828d3a0c2b5524/cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper) (3.9.0)\n",
      "Collecting lit (from triton==2.0.0->openai-whisper)\n",
      "  Downloading lit-17.0.2.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/154.6 kB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper)\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/50/df/38c9fb5cc64f4fcc0577a14a0665c2a5de74f45a621ac7708320b1ac80c6/llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.27.6-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper, lit\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=4327352e2dc9142bf945a8833e1e168aa007cc6a3491f2ed27ced1aa5b3562a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.2-py3-none-any.whl size=93257 sha256=90a4c66cc12bb5bac2ba7d0e181110c385bb572b9f646377f77c42e7f9912937\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2exc9rj/wheels/3a/ff/73/ce1a12d89231e9ac175fb6493ee1fcc8768e85ee3bea4b98b2\n",
      "Successfully built openai-whisper lit\n",
      "Installing collected packages: lit, cmake, numpy, llvmlite, tiktoken, numba, triton, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "Successfully installed cmake-3.27.6 lit-17.0.2 llvmlite-0.41.0 numba-0.58.0 numpy-1.25.2 openai-whisper-20230918 tiktoken-0.3.3 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install moviepy\n",
    "!pip install openai-whisper --no-cache-dir\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGFfud7iN8td",
    "outputId": "e9d60480-7b5b-4947-d7f6-624e055ec124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper model loaded.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import whisper\n",
    "import openai\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# openai 엄지호 api key \n",
    "openai_api_key = \"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\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# gpt_model = \"gpt-3.5-turbo-16k\"\n",
    "gpt_model = \"gpt-4-1106-preview\"\n",
    "temperature = 0.3\n",
    "\n",
    "# 모델 로드\n",
    "model = whisper.load_model(\"large\")\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"초를 'HH:MM:SS.mmm' 형태로 변환\"\"\"\n",
    "    return '{:02}:{:02}:{:02}.{:03}'.format(\n",
    "        int(seconds // 3600),\n",
    "        int(seconds % 3600 // 60),\n",
    "        int(seconds % 60),\n",
    "        int((seconds % 1) * 1000)\n",
    "    )\n",
    "\n",
    "def transcribe_audio(audio_file_path, output_directory):\n",
    "    transcribe = model.transcribe(audio=audio_file_path)\n",
    "    segments = transcribe['segments']\n",
    "\n",
    "    # 자막 파일 이름을 포함한 경로 설정\n",
    "    srt_filename = os.path.join(output_directory, \"subtitle_\"+ audio_file_path[-5:-4]+ \".srt\")\n",
    "    with open(srt_filename, 'w', encoding='utf-8') as srt_file:\n",
    "        for idx, segment in enumerate(segments, 1): # srt 세그먼트에 인덱스를 부여하기 위해 enumerate 사용\n",
    "            start_time = format_time(segment['start'])\n",
    "            end_time = format_time(segment['end'])\n",
    "            text = segment['text']\n",
    "            srt_file.write(f\"{idx}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "    \n",
    "    return srt_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 영상 시간만 자르는 함수\n",
    "def extract_times(text):\n",
    "    # 정규 표현식을 사용하여 시간 정보 추출\n",
    "    pattern1 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} --> \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern2 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} - \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern3 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3}부터 \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    pattern4 = r'\\d{2}:\\d{2}:\\d{2}.\\d{3} ~ \\d{2}:\\d{2}:\\d{2}.\\d{3}'\n",
    "    \n",
    "    matches1 = re.findall(pattern1, text)\n",
    "    matches2 = re.findall(pattern2, text)\n",
    "    matches3 = re.findall(pattern3, text)\n",
    "    matches4 = re.findall(pattern4, text)\n",
    "    \n",
    "    match1 = [m1.replace(\" --> \", \"-\") for m1 in matches1]\n",
    "    match2 = [m2.replace(\" - \", \"-\") for m2 in matches2]\n",
    "    match3 = [m3.replace(\"부터 \", \"-\") for m3 in matches3]\n",
    "    match4 = [m4.replace(\" ~ \", \"-\") for m4 in matches4] \n",
    "    \n",
    "    times = match1 + match2 + match3 + match4\n",
    "    \n",
    "    # times = [t.replace(\" - \", \"-\") for t in match]\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_summerized_timeline(video_file_path, summerized_subtitle_file_path, summerized_timeline_list):\n",
    "    if os.path.exists(video_file_path):\n",
    "        filename = \"summerized_subtitle_\" + video_file_path[-5:-4] + \".csv\"\n",
    "        print(f\"파일명 '{filename}'으로 저장됨.\")\n",
    "    else:\n",
    "        filename = \"summerized_subtitle_default.csv\"\n",
    "\n",
    "    # 타임라인만 파일로 만들어서 저장\n",
    "    filename = os.path.join(summerized_subtitle_file_path, filename)\n",
    "    \n",
    "    # 리스트의 모든 항목을 하나의 문자열로 연결하고 작은 따옴표를 제거\n",
    "    csv_timeline = ','.join(summerized_timeline_list).replace('\\'', '')\n",
    "    \n",
    "    # 파일에 저장\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(csv_timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "if9HoORUPSy9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# text로 생성된 자막 받아와서 GPT에 요약 요청하는 함수\n",
    "def get_summerize_text(text):\n",
    "  messages1 = []\n",
    "  content1 = \"\"\"\n",
    "     다음 글은 시사뉴스 자막인데 자막이 진행되는 시간과 자막 내용을 줄거야.\n",
    "     그러면 너는 전체 자막 내용을 요약해줘\n",
    "  \"\"\"  + text\n",
    "\n",
    "  completion1 = openai.ChatCompletion.create(\n",
    "      model=gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content1}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response1 = completion1.choices[0].message.content\n",
    "  print(\"Sumerizing Subtitle Succesful ==================================================\")\n",
    "\n",
    "  messages2 = []\n",
    "  content2 = \"\"\"\n",
    "    내가 첫 번째로 요약된 내용의 글을 줄거야 그러면 너는 2번째로 받은 글에서 요약된 내용을 찾아서 자막 타임라인을 알려줘. \n",
    "    타임라인은 '\\d{2}:\\d{2}:\\d{2}.\\d{3}' 이런 형식으로 저장되어 있어.\n",
    "    몇 분 몇 초부터 몇 분 몇 초인지 알려줘.\n",
    "  \"\"\" + chat_response1 + \"\"\"다음 글에서 위의 내용을 찾아서 타임라인에 매칭시켜줘.\"\"\" + text\n",
    "    \n",
    "  completion2 = openai.ChatCompletion.create(\n",
    "      model = gpt_model,\n",
    "      messages = [\n",
    "          {\"role\":\"user\", \"content\": content2}\n",
    "      ],\n",
    "      temperature = temperature\n",
    "  )\n",
    "  chat_response2 = completion2.choices[0].message.content\n",
    "  print(\"Matching Timeline Succesful ==================================================\")\n",
    "  # 요약되고 타임라인 매칭된 자막 return\n",
    "  return chat_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9LSHPUTWkkU",
    "outputId": "4991810d-5ddd-4561-a1d6-f28dddd01051",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 마지막에 이 함수 하나만 실행하면 모든게 가능하게 만들기 \n",
    "# video_file_path - 비디오 파일이 있는 경로 및 이름 .mp4로 끝나야 함, audio_file_path - 오디오 저장 경로 및 이름 .mp3로 끝나야 함\n",
    "# subtitle_file_path - 생성된 자막 저장할 경로(폴더), summerized_subtitle_file_path - 요약된 자막 저장 경로(폴더)\n",
    "def auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path):\n",
    "    video = VideoFileClip(video_file_path)\n",
    "    # video to audio\n",
    "    ffmpeg_extract_audio(video_file_path, audio_file_path)\n",
    "    print(\"Complete generating audio file\")\n",
    "    # srt subtitles\n",
    "    srt_output = transcribe_audio(audio_file_path, subtitle_file_path)\n",
    "    print(f\"SRT 자막 파일이 생성되었습니다: {srt_output}\")\n",
    "    # SRT 파일 경로 설정\n",
    "    srt_file_path = srt_output\n",
    "    \n",
    "    # SRT 파일 열기\n",
    "    with open(srt_file_path, 'r', encoding='utf-8') as srt_file:\n",
    "        srt_contents = srt_file.read()\n",
    "    \n",
    "    # 생성된 자막 요약 시작 및 타임라인 매칭\n",
    "    summerized_text = get_summerize_text(srt_contents)\n",
    "\n",
    "    # 요약된 자막 및 타임라인 출력\n",
    "    print(\"타임라인에 매칭된 요약된 자막\\n\" + summerized_text)\n",
    "    \n",
    "    # 요약된 자막에서 타임라인만 추출\n",
    "    times = extract_times(summerized_text)\n",
    "    print(\"타임라인만 추출\\n\")\n",
    "    print(times)\n",
    "    # 타임라인 summerized_subtitle_file_path에 저장\n",
    "    save_summerized_timeline(video_file_path, summerized_subtitle_file_path, times)\n",
    "    \n",
    "    # # 추출된 시간 출력\n",
    "    # for start_time, end_time in times:\n",
    "    #     print(f\"Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "    # 2차원 리스트로 추출된 시간 return\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Complete generating audio file\n",
      "SRT 자막 파일이 생성되었습니다: subtitle/subtitle_2.srt\n",
      "Sumerizing Subtitle Succesful ==================================================\n",
      "Matching Timeline Succesful ==================================================\n",
      "타임라인에 매칭된 요약된 자막\n",
      "요약된 내용에 해당하는 자막 타임라인은 다음과 같습니다:\n",
      "\n",
      "- 대한민국의 합계 출산율이 0.7명으로 전 세계에서 가장 낮으며, 0.6명대 진입이 임박했고 OECD 국가 중 가장 낮습니다.\n",
      "  - 00:00:00.000 --> 00:00:07.200\n",
      "  - 00:00:28.359 --> 00:00:36.460\n",
      "\n",
      "- 인구 감소와 고령화 문제가 심각하여 국민연금 부담 증가, 어린이집이 요양원으로, 결혼식장이 장례식장으로 바뀌는 상황이 발생하고 있습니다.\n",
      "  - 00:00:36.539 --> 00:00:45.539\n",
      "  - 00:00:45.739 --> 00:00:51.640\n",
      "\n",
      "- 인구 구조가 2043년까지 역피라미드 형태로 바뀔 가능성이 높으며, 인구 감소 속도가 빨라질 것입니다.\n",
      "  - 00:00:59.560 --> 00:01:05.640\n",
      "  - 00:01:05.719 --> 00:01:10.920\n",
      "\n",
      "- 인구 감소는 경제에 부정적 영향을 미치며, 경제 활동 인구 감소로 생산과 소비가 줄어들 것으로 예상됩니다.\n",
      "  - 00:01:22.920 --> 00:01:29.679\n",
      "\n",
      "- 부동산 시장에서는 인구 감소에도 불구하고 1인 가구 증가로 인한 주택 수요가 늘고 있으며, 수도권 부동산은 좋은 투자처로 여겨지고 있습니다.\n",
      "  - 00:01:46.319 --> 00:01:55.420\n",
      "  - 00:01:55.500 --> 00:01:58.679\n",
      "  - 00:02:31.840 --> 00:02:36.560\n",
      "\n",
      "- 지방 부동산은 양극화가 심화되고 있으나, 좋은 일자리와 학군이 밀집된 지역의 부동산 가격은 오히려 상승하고 있습니다.\n",
      "  - 00:02:49.939 --> 00:02:55.340\n",
      "  - 00:02:55.419 --> 00:03:04.019\n",
      "\n",
      "- 청년들은 높은 집값 때문에 결혼과 출산을 망설이고 있으며, 정부의 신혼부부 지원 정책은 큰 효과를 보지 못하고 있습니다.\n",
      "  - 00:03:09.139 --> 00:03:14.939\n",
      "  - 00:03:15.019 --> 00:03:21.919\n",
      "  - 00:03:37.860 --> 00:03:45.360\n",
      "\n",
      "- 일본의 경험을 바탕으로, 대한민국도 인구 감소와 부동산 문제를 해결하지 못한다면 장기 불황에 빠질 위험이 있음을 경고하고 있습니다.\n",
      "  - 00:04:02.520 --> 00:04:07.620\n",
      "  - 00:04:07.700 --> 00:04:12.340\n",
      "  - 00:04:47.879 --> 00:04:53.180\n",
      "  - 00:04:53.419 --> 00:04:57.019\n",
      "  - 00:04:57.099 --> 00:05:04.920\n",
      "\n",
      "위의 타임라인은 요약된 내용과 일치하는 부분의 시작과 끝 시간을 나타냅니다.\n",
      "타임라인만 추출\n",
      "\n",
      "['00:00:00.000-00:00:07.200', '00:00:28.359-00:00:36.460', '00:00:36.539-00:00:45.539', '00:00:45.739-00:00:51.640', '00:00:59.560-00:01:05.640', '00:01:05.719-00:01:10.920', '00:01:22.920-00:01:29.679', '00:01:46.319-00:01:55.420', '00:01:55.500-00:01:58.679', '00:02:31.840-00:02:36.560', '00:02:49.939-00:02:55.340', '00:02:55.419-00:03:04.019', '00:03:09.139-00:03:14.939', '00:03:15.019-00:03:21.919', '00:03:37.860-00:03:45.360', '00:04:02.520-00:04:07.620', '00:04:07.700-00:04:12.340', '00:04:47.879-00:04:53.180', '00:04:53.419-00:04:57.019', '00:04:57.099-00:05:04.920']\n",
      "파일명 'summerized_subtitle_2.csv'으로 저장됨.\n",
      "['00:00:00.000-00:00:07.200', '00:00:28.359-00:00:36.460', '00:00:36.539-00:00:45.539', '00:00:45.739-00:00:51.640', '00:00:59.560-00:01:05.640', '00:01:05.719-00:01:10.920', '00:01:22.920-00:01:29.679', '00:01:46.319-00:01:55.420', '00:01:55.500-00:01:58.679', '00:02:31.840-00:02:36.560', '00:02:49.939-00:02:55.340', '00:02:55.419-00:03:04.019', '00:03:09.139-00:03:14.939', '00:03:15.019-00:03:21.919', '00:03:37.860-00:03:45.360', '00:04:02.520-00:04:07.620', '00:04:07.700-00:04:12.340', '00:04:47.879-00:04:53.180', '00:04:53.419-00:04:57.019', '00:04:57.099-00:05:04.920']\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용 예시\n",
    "video_file_path = \"./video/video2.mp4\" # .mp4 파일로 끝나는 path\n",
    "audio_file_path = \"./audio/audio2.mp3\" # .mp3 파일로 끝나는 path\n",
    "subtitle_file_path = \"subtitle\" # 폴더로 끝나는 path\n",
    "summerized_subtitle_file_path = \"summerized_subtitle\" # 폴더로 끝나는 path\n",
    "print(\"================================================\")\n",
    "\n",
    "result_times = auto_editing_video(video_file_path, audio_file_path, subtitle_file_path, summerized_subtitle_file_path)\n",
    "print(result_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 코드 실행할 때마다 이전에 있던 파일 삭제하고 다시 만들기 \n",
    "# -> video1.mp4 -> 1.txt 로 summerized txt 파일 만들기 \n",
    "# TODO: 비디오 길이 n분 이상 안넘어가도록 요약하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브에서 링크로 동영상 다운로드 받는 코드\n",
    "# from pytube import YouTube\n",
    "# DOWNLOAD_FOLDER = \"./\"\n",
    "# url = \"https://www.youtube.com/watch?v=7DbtZY9Kd6Q\"\n",
    "# youtube = YouTube(url)\n",
    "# stream = youtube.streams.get_highest_resolution()\n",
    "# stream.download(DOWNLOAD_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
